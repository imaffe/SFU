## Operating Systems Final Review

#### 1. Introduction : kernel & system call

- interrupt
  - interrupt service routine: ISR are stored at a known memory locations。 Interrupt number is mapped to an entry in  interrupt vector where the entry contains the address of an ISR in memory
  - Interrupts are generated by **hardware** devices
- traps
  - traps are software-generated interrupts due to :
    - divide by zero, illegal memory access
    - request for os services(system calls)
    - Q: is system call a ISR ? what is the rel
- user and kernel
  - kernel mode can execute privileged instructions
  - hardware execute privileged instructions only in kernel mode
    - if not in kernel mode, hardware raises an interrupt, and switch system in kernel mode
    - OS ensures safety and correctness before execution
- system calls : kind of trap
  - Definition : user access privileged instructions using system calls 
    - when interrupt/trap/exception is generated, the control is transferred to the OS
  - API : often executed through API
    - **printf ()** calls **write ()** system call, and mapping is done by standard C library
    - **strace -c ls** can be used to display summary info on system calls invoked during the execution of  the command **ls**
  - Protection : Timer Chip ( Hardware )
    - when the user program use resource more than the set time chip issues interrupt. So this can OS regain the control. Then OS decides to whether give more time or terminate it.
- exception : TODO what is exception
- OS structures
  - Monolithic Structure : Too much in one layer
  - Layered Structure : trick to design the layer if two layer use each other/ each layer use only lower layer service.
  - Microkernel Structure : provide minimal services, rest in user space. Modules communicate using message passing(through kernel),  Easier to extend microkernel and port to new architectures, but will have performance over head.
  - Modular Structure :   Implement OS as separate components, and other modules are linked to kernel as needed. Most OS are implemented this way. Flexible and efficient
  - Hybrid Structures
- System Boot
  - OS must be started by hardware
  - On powered up the instruction register is loaded with a predefined memory location
  - Bootstrap loader routime
    - load the boot block on the disk to memory 
    - boot block load the rest of the loader
    - the loader loads kernel

#### 2. Processes and Threads

##### Process

- Components : at least Program Counter / Stack / Data section

- The Graphic View of a process : in slides 

- Process State 

  - new
  - running : if receive interrupt, it will go to the ready queue
  - waiting ： waiting for some event to occur, like IO  or event completion
  - ready ：process is waiting for CPU scheduler dispatch.
  - terminated
  - TODO : what is the difference between waiting and ready

- Process Control Block

  - Components:

    - Process State
    - Program Counter
    - CPU registers
    - CPU scheduling info
    - Memory-management info
    - Accounting Info
    - I/O status

  - Usage : Switch CPU from one process to another

  - PCB in linux 

    ```c
    struct task_struct{
        pid_t pid;
        long state;
        unsigned int time_slice; //scheduling information
        struct task_struct * parent;
        struct list_head children;
        struct files_struct * files; // list of open files
       	struct mm_struct *mm;  // address space of this process
    }
    ```

  - ready queue : set of all processes in main memory, ready to be execute

  - waiting queue : TODO is this reside in disk

  - device queues : processes waiting for I/O device

  - I/O queue : TODO : is I/O queue the same as waiting queue?

  - scheduling queues : TODO the graphical view of the whole procedure

  - Context Switch : save state of one PCB in memory, and load another's information into registers, state means CPU registers like stack pointer and program counter

  - Fast Context Switch : use hardware support with multiple register sets, only need to change pointer to complete context switch

- Process Creation

  - Process Tree : has parents and children

  - **fork()** system call to create a child process. Child is a copy of the parent,

  - **exec ()** system call to load another program into its address space.

  - parents wait for children to terminate 

  - Q : can we not wait ? Is is a default wait? what is the NULL in program means

    ```c
    int main(){
        pid_t var_pid;
        var_pid = fork(); 
        // fork and return the pid of the child process to parent
        // return 0 to child process
        if(var_pid < 0){ // error when pid < 0
            fprint (stderr, "fork failed");
            exit(-1);
        }
        else if(var_pid == 0){ // means this is a child process
            
            execlp("/bin/ls", "ls", NULL);
        }
        else{
            // TODO what should the var_pid be : the pid of child?
            wait(NULL);
            printf("Child %d Completed", var_pid);
            exit(0);
        }
    }
    ```

- Process Termination

  - **exit()** execute last statement and ask OS to delete it
  - **abort()** terminate the execution of children process : can have **cascade** termination
  - zombie process: child terminated but parent hasn't called wait(), and return value stay in mem.
  - orphan process: Parents exited without calling wait(), linux use adoption by init process?
  - Q : what is the '&' operand in shell mean and what was executed when doing this?
    - this question is quite meaningless

##### Threads

- Definition : basic unit of CPU utilization, must have Program Countre, Register set and set at least.

- Share Section : Code section,Data Section, OS resources like open files and signals

- Q : is code section part reside in disk?

  - 1st answer: of course not, a process can be called a process only when it's read into the memory, so wait queue and ready queue all stays in memory
  - 2nd answer : the  1st answer is wrong. Wait queue might be in memory, but the process (and its code section)

- Q : How signals share among threads ? Who is in charge of allocate signals to threads.

- Thread Models

  - User level threads

    -  All data structures are maintained in user level
    - All thread operations are performed in user mode
    - kernel knows nothing about user-level threads
    - provided by user-level libs

  - Kernel level threads

    - All data structure are maintained in kernel space
    - All thread operations have to be in kernel mode (need system calls to perform them)
    - Provided by the OS

  - Many to One : managing user  threads is faster, no system calls, and no switching to kernel mode

  - One to One : increased concurrency, and when one thread blocks the other can run, but create too many kernSignalsel thread degrade performance because they consume OS resource.

  - Many to Many : Need a thread scheduler. When a user thread blocks, the kernel notifies thread scheduler (using upcall) to select another thread to use the free kernel thread

    ```c
    // Pthread Example
    #include <pthread.h>
    int sum;
    void * runner(void * param){
        int i, upper = atoi(param);
        sum = 0;
        for（i = 1; i <= upper; i++）{
            sum += i;
        }
        pthread_exit(0);
    }
    
    int main(int argc, char * argv[]){
        pthread_t tid;
        pthread_attr_t attr;
        pthread_attr_init(&attr); // using default settings
        pthread_create(&tid, &attr, runner ,argv[1]);
        pthread_join(tid, NULL); // waitign for the thread to be done
    }
    ```

- fork() : if exec() executed right after fork(), no need to duplicate all threads, else all threads should be duplicated

- Signals : synchronous or asynchronous

  - generated by an event, and delivered to a process.

  - Signal handler can be OS or user-defined 

  - TODO : how to write a signal handler

    ```c
    void handle_SIGINT(){
    	// do anything
        exit(0);
    }
    int main(int argc, char * argv[]){
        struct sigaction handler;
        handler.sa_handler = handle_SIGINT; // register handler
        sigaction(SIGINT, &handler, NULL);
        while(1)
       	return 0;
    }
    ```

    - Q : what is the difference between signals and trap? one switch to kernel mode and one might not?
    - asynchronous generated by external event like Ctrl-C. Synchronous generated by threads like division by 0.

  - Threads can choose to block signals.

- TODO : Difference between Interrupts and signals and traps and exceptions

- Thread Pools : very common in modern 

- Linux Thread

  - Do not need to create threads when requried.
  - Linux refers to threads and process as tasks
  - Thread creation is done through **clone** system call
  - clone : 1. can have no sharing resources 2. share of all resources between parent and child. So 1 is like process and 2 is like threads

#### 3. CPU Scheduling

- CPU/IO Burst Cycle
  - Q : where is process in when in I/O wait , waiting queue or ready queue?
- Two or Three level scheduler: 
  - job scheduler decide which processes go to memory(ready queue)
  - CPU scheduler decide which job in ready queue to execute
  - Medium Term scheduler, move some partially-executed jobs from memory to disk.
  - Q : where is I/O queue? what is the difference between I/O queue and waiting queue ? Does I/O queue has a scheduler too? 
- Long-term scheduler (job scheduler)
  - Controls the degree of multiprogramming
  - invoked infrequently
  - job is to maintain a good mix of CPU-bound and I/O bound jobs in the system
- Short Term scheduler (CPU scheduler) : Main Focus
  - invoked very frequently, and must be fast
- Two schema of CPU scheduler
  - preemptive
    - Can force a process to stop at any time of execution.
    - Q : will it be put into ready queue or other places?
    - Preemptive is more difficult to implement because maintain consistency between shared data and it might need hardware support. If preempt a system call it might need to store kernel structures.
  - nonpreemptive
    - does not leave once allocated CPU unless : has to wait like I/O or child process to terminate
    - it self terminates
- Dispatcher : scheduler only point out which to execute, dispatcher do the real work
  - including
    - Context switch
    - switch to user mode
    - jump to proper location
  - Dispatch latency, time it takes for the dispatcher to stop one process and start another
- Scheduling Criteria : strategies
  - Maximize CPU utilization
  - Maximize Throughput
  - Minimize Turnaround Time
  - Minimize Waiting Time
  - Minimize Response Time
- 5 Scheduling Algorithms
  - FCFS : first come first served, will cause convoy effect
  - SJF : shortest job first, need to know the next CPU burst length
    - Burst Length Prediction
    - Q : why do we need to know the next?
  - SRTF : Shortest remaining time first
  - Priority Based : can cause starvation, can use aging to avoid starvation
  - Round Robin : (**important**)
    - total n process, each process execute 1/n time, this time called q.
    - if used up, added to the end of ready queue
    - q large : FCFS     q small : high overhead for context switch
    - 80% CPU bursts should be shorter than time quantum
  - Multilevel Queue(**important**)
    - process can change between queues
    - multilevel feedback queue, lower queue run only when higher priority queue is empty
    - 8ms ->16ms ->FCFS , if 8ms RR not finish then move to 2nd queue with 16ms quantum
    - This cause short processes served faster,  and long process sink to bottom FCFS queue bring 
    - more through put
- Multiprocessor Systems:
  - a CPU can has multiple cores, and a core can have multiple kernel threads.
  - Asymmetric multiprocessor : One master processor do the scheduling for others
  - Symmetric multiprocess, each processor run its own scheduler. One ready queue for all processors or separate ready queue for each.
- SMP issues
  - Processor Affinity : if bound to a CPU, better not change because cause of context switch is high
  - Load Balancing : guarantee evenly distribution among processors
    - Push migration : a task check load and moving tasks
    - Pull : a free processor pulls a task from busy processor
- Real Time Scheduling
  - Earliest deadline first hard-real-time
  - quickly, priority based scheduling with preemption
- Linux : Completely Fair Schedulers (CFS)
  - select task with lower virtual run time, O(logN) with red-black tree , O(1) with caching

#### 4. IPC & Synchronization

##### Interprocess Communication (IPC)

- Shared Memory : one process creates shared memory, other process attach shared memory to their own memory address
  - POSIX : shm_open(), mmap()
- Message Passing
  - Send messages via **kernel** send(msg), receive(msg)
  - TODO what is Naming vs Ports/Mailbox
  - TODO what is Block vs NonBlocking
  - Buffering

##### Synchronization

- Describe a race condition using  instruction level

- Three condition for solving Critical Section  Problem
  - Mutual Exclusion
  - Progress
  - Bounded Waiting
  - solutions : Disable interrupts during running CS , but will cause unresponsive situation
    - currently running  code executes without preemption

- Peterson's Solution : Software

  - Assuming that LOAD and STORE instructions are atomic

  - ```c
    do{
        flag[i] = true;
        turn = j;
        while(flag[j] && turn == j);
        //critical section
        flag[i] = false;
        //remainder section
    } while(true)
    ```

  - Q : why set turn to j not i ??

  - turn and flag are shared variables

- Synchronization hardware : atomic instructions

  - test_and_set() : test a memory value and set its value

    - ```c
      bool test_and_set(bool * target) {
          bool rv = *target;
          *target = TRUE;
          return rv;
      }
      
      // shared lock is initialized to FALSE
      do{
          while(test_and_set(&lock));
          //critical section
          lock = FALSE;
          //remainder section
      } while(true);
      // but will cause indefinite waiting
      ```

    - 

  - compare_and_swap() : swap contents of two memory words if a condition is satisfied

    - ```c
      int compared_and_swap(int *value, int expected, int new_value){
          int temp = *value;
          if(*value == expected)
              *value = new_value;
          return temp;
      }
      
      do {
          while(compare_and_swap(&lock, 0 ,1));
          // critical section
          lock = 0;
          //remainder section
      } while(true);
      ```

- Mutual Execution Locks :  Mutex

  - ```c
    acquire(){
        while(!available)
            ;
        available = false;
    }
    // 
    release(){
        available = true;
    }
    ```

  - this is a spinlock implementation, while waiting it will consume CPU

  - advantage : no context switching, useful when CS is small code

- Semaphores

  - ```c
    wait(S){
        while(S <= 0)
            ;
        S--;
    }
    signal(S){
        S++;
    }
    // non-block version
    wait(semaphore * S){
        S->value --;
        if(S < 0){
            add to wait list;
            block();
        }
    }
    signal(semaphore * S){
        S->value ++;
        if(S ->value <= 0){
            remove a process P from wait list;
            wakeup(P)
        }
    }
    ```

  - S should be initialized to 1

  - we can also have a non-busy waiting implementation

    - using s list structure
    - block() : suspend the process that invokes it (place the process in the waiting queue)
    - wakeup() : resumes the execution of blocked process. (move from waiting queue to ready queue)
    - TODO : review this part and why <0 or <=0

  - wait and signal become CS (must be protected)

    - disable interrupts 
    - Q : why this only work in uniprocessor systems
    - busy waiting or spinlocks : multiprocessor systems

  - if want to use semaphore to make sequencial excution : semaphore must be init to 0

  - some issues :

    - signal wait : then no CS protection, multiple CS execute at same time
    - wait wait : deadlock possible

- Bounded Buffer( Producer - Consumer Problem)

  - ```c
    while(true){
        wait(empty);
        wait(mutex);
        //add item to buffer
        signal(mutex);
        signal(full);
    }
    
    //consumer
    while(true){
        wait(full);
        wait(mutex);
        // remove
        signal(mutex);
        signal(empty);
    }
    ```

  - TODO : how to declare these semaphore types?

  - mutex init to 1

- Readers-Writers Problem

  - rw_mutex = 1; mutex = 1; read_count = 0;

  - ```c
    //reader
    while(true){
        wait(mutex);
        read_count++;
        if(read_count 
    }
    ```

  - when there is a reading, no write permitted

  - Q : why there cannot be multiple reader read the same part? at a time there would be only one  reader at a time but that is not good

    - explained at next few questions

  - maybe because there are deadlock if there are multiple waits rw_mutex

  - Q : there is a serious question, why use two mutex part in reader procedure?

    - to ensure multi-thread processing

  - Q : what will happen if a seconder reader added read count but never waited for the rw_mutex

    - answered in next question

  - still go into reading part ? this is good because when read_count is bigger than 1 there is no need to have the rw_mutex again, it still can be critical section.

  - Good for application with more readers than writers, with reader_write lock

  - read write lock require more overhead to establish than semaphores 

  - Q : why?

    - no why , just remember it

- Dining-Philosophers Problem

  - ```c
    
    ```

  - solution :pick chopsticks only if both are available

  - TODO : implement this in code

  - odd philosopher picks left chopstick first,

- Monitors

  - a high-level abstraction for process synchronization : compliler takes care of mutual exclusion
  - Q: what will happen if no wait and then signal of condition ?
  - signal will have no effect if no process is suspending

- Synchronization and priorities

  - ORIORITY INHERITANCE

#### 5. Deadlocks

- Four conditions of deadlock

  - mutual exclusion
  - no preemption
  - hold and wait
  - circular wait

- Resource Allocation Graph

- Deadlock Prevention 

  - To break one of the four conditions to make deadlock never happen, like static guarantee
  - Hold and wait
    - solution 1 : a Process requests a resource only if it does not hold other resources
    - solution 2 : request all of its resource at beginning of execution
    - disadvantage : very low resource utilization, starvation possible
  - circular wait
    - impose a total ordering on all resource types,requests resources only in increasing order of ID
  - no preemption
    - Resources whose states cannot be easily saved
    - Q : why this is not easily saved
    - Atomicity
    - Q : why this break atomicity

- Deadlock Avoidance

  - check if possible deadlock during assignment, like dynamic guarantee
  - each process declares the maximum number of resources of each type that it may need
  - OS decide if the pretend issue result the system in a safe state
  - Safe State
    - Definition of Safe State
    - TODO : explain this safe state definition : ordering of resources

- Resource Allocation Algorithm : for single resource

  - dash line : future claim edge,  and request edge, assignment edge
  - Q : the definition of slide 20 is wrong ?

- Banker' Algorithm

  -  Data Structure specification	
       -  Available[i] = k :  instances of current left resources of type i is k 
       -  Max(i)[j] = k : Pi will need k instance of resource j
       -  Allocation(i)[j] : Pi currently has k instance of resource j
       -  Need(i)[j] : Can be obtained by max and allocation array
  -  Safe-state algorithm
     -  Let Work = Available
     -  Finish[i] = False at first
     -  Work stores the possible available resource, if a process can finish under current Work array, then add all allocated resource of Process i to work array , and find next possible process that can finish job under new Work array. If all finish can be true, then safe
  -  Resource Request algorithm
     -  decide if the allocation can happen
     -  Q : do we decide on request or assignment ?
     -  if request smaller bigger than available , then cannot allocate, otherwise
     -  Pretend the request can be done
     -  then do the request 
     -  Q : suppose the request result in safe state : add a request edge or assignment edge ?

- Deadlock Detection and recovery

  - or some OS ignore the problem and pretend deadlock never happen
  - TODO : the detection algorithm on book
  - when to invoke : depends on how often a deadlock is likely to occur
    - once every hour or when CPU utilization is less than a number
    - on for each disjoint cycle will need to be rolled back
  - Recovery 
    - abort all
    - abort one process at a time until the deadlock cycle eliminated
  - Victim Choice
    - priority, how longer to complete : kill new beginners
    - always kill the one who has executed least
    - can cause starvation if always chosen as victim


#### 6. Memory Management

- Main Memory and register are the only storage that CPU can access directly (caching can be used)
- Three way of binding instruction and data to memory
  - Compile time
  - Load time
  - Execution Time
  - Q : Give a example of load time and execution time 
  - Logical and physical address space differ only binding happens in execution
- Memory Management Unit( MMU)
  - hardware : runtime mapping logical to physical address
  - and ensures memory protection using base and limit registers, only kernel code can change the value of the register
- Memory Allocation : usually divided to 2 part, one for OS one for user processes
  - Contiguous Allocation vs Non-contiguous memory allocation (paging)
- Contiguous Allocation
  - OS maintain information about allocated partitions and free partitions
  - First Fit : find first hole that can hold
  - Best Fit : find smallest hole that can hold
  - Worst Fit : find largest hole that can hold
  - Pros : easy to implement, Cons : Memory Fragmentation
  - Q : Internal or External? External! Internal occurs when paging is used.
  - Can use memory compaction to avoid Memory Fragmentation
- Paging 
  - page table : translate logical to physical addresses
  - Q : where is page table? every process has one? kernel or user keeps this? when was it loaded? why there is paging hardware? 
  - What is paging hardware?
  - Address Translation : Do the math
  - Implementation of Page Table
    - page table is kept in main memory : but this will cause every memory access requires two memory access.
    - TLB : Translation look-aside buffer : stores part of the page table , Hardware
      - if TLB is full need OS to replace. However some entries in TLB are wired down.
      - Each entry stores address space Identifier (ASID) so that entries for different processes can be held simultaneously. 
  - Calculation of Effective access Time.
  - Memory Protection
    - Use several bits to indicate page's authority. Add  another bit valid/invalid bit to indicate whether the page is in the process's address space
    - Q : every process has a page table or has process id to indicate which one belongs to a certain process.
      - every process has a page table
    - illegal memory access will trap to OS
    - Page table length register to limit size
  - Shared pages : shared code, must appear in the same location in the logical address of all process
  - Q : why in the same location in the logical address rather than physical address?
  - Need to know how to calculate the size and structure of a page table.
  - Hierarchical page table implementation, but notice the extra memory access overhead.
    - Why 4 byte entry
  - Hashed Page Tables
    - each element has virtual page number
    - mapped page frame number
    - pointer to next element
  - Inverted Page Table
    - using process id and virtual page number to search the required page.
    - can use hash table to reduce the search time
    - Q : how to use hash table to do this? hash to one of physical memory entries and mark down the physical page number in the list head?
    - But it is difficult to implement shared page
- Segmentation
  - divide memory from user's view
  - Segmentation Architecture
    - <segmentation Number, offset>
    - using segment table to map logical to physical.
    - Each entry has base and limit information to represent a segmentation
    - every time a logical address is checked if beyond segmentation
    - Cons : dynamic memory allocation problem. External Fragmentation
    - Can combine segmentation with paging
- Intel 32  architecture
  - use both segmentation and paging
  - first go to segmentation to produce a linear address
  - linear address given to paging unit to generate physical address
  - Q : do we have a segmentation table for each process ? and load it as the page table?
  - Segment up to 4 GB (2^32 byte)
  - Max number of segments per process 2^14 ,half for private , half for shared 
  - 13 bit seg, 1 bit private or shared, 2 bit for page?
  - Q : what does the q mean of the last 2 bits
  - Pagesize 4KB or 4 MB; Two level paging : 10 for page table 1, 10 bit for page table 2, 12 for offset.
- Page Address Extensions (PAE)
  - Q : What does base address mean? Added a extra register to denote which part?

#### 7. Virtual Memory

- Process Virtual Address Space

  - Q : is the graph show the logical memory? why do we load shared libraries and where would libs belong to if not this structure? Which part should libs belong to?

- Demand Paging

  - valid-invalid bit to denote whether in memory or not
    - Q : how to decide whether it is Page Fault or illegal reference of memory?
    - TODO how many memory access would occur if the worst case in a Page Fault ?
  - **Important**  how to handle restart instruction causing overlapping? and solution
  - Major latency comes from reading new page from disk **pay attention to units !! milliseconds**
  - Copy-on-write technique : act when doing fork()

- Major vs Minor page fault

  - major : need to bring page from disk

  - minor, do not need to bring page from disk, like shared page that just hasn't been linked but already in memory or dynamic memory allocation where kernel may not actually allocate physical memory until it is accessed.

    ```shell
    # some commands
    ps -eo min_flt,maj_flt,pid,cmd
    /usr/bin/time -v ls
    vmstat
    getconf PAGESIZE
    ```

- Page Replace Algorithms

  -  Q : how many system calls during a certain execution? How many will happen when a page replacement happen. Which mode OS is in when doing each stage.
  -  FIFO : cause Belady's Anomaly
  -  Optimal : Do some exercise 
     -  replace page that will not be used for longest period of time
  -  LRU
    - counters implementation : but will has overflow, need hardware support
    - stack: need hardware support
    - cannot use software because interrupts are very costly
  -  CLOCK
     -  TODO : how to do this
  -  LFU and MFU

- Allocation of frames : how many pages a process at least have

  - Proportional allocation using priorities rather than size
  - Global replacement : choose from all frames, can take frame from other process
  - Local replacement: can have have page fault rage even other process has extra
  - Q : local replacement means the it only replace its own frames.

- Thrashing

  - leads to : low  CPU utilization and more page switching than executing.
  - Models to solve Thrashing : Locality Model : decide the most recently used codes
  - Working-Set model.
    -  OS monitors the WS of each process
    - allocate WS size number of frames to each process
    - if we have left memory space we can start another process
    - TODO : the way to estimate the size of WS with interval timer and reference bit
  - Another way to control thrashing : using page fault rate
    - monitor page-fault rate and add frame or delete accordingly
    - Q : is this Global Allocation?

- Allocating Kernel Memory

  - some kernel memory needs to be continuous,
  - kernel will keep structures !
  - Q : why structures make kernel special? because dynamically allocated
  - virtual memory is expensive for kernel memory

- Using Free Frame Pool to kernel pool

  - Buddy system
    - using sub blocks using power-of-2 size. and can combine adjacent blocks
  - Slab system
    - a slab is one or more physically contiguous pages
    - a cache is for each unique kernel data structure
    - no fragmentation and fast memory allocation
    - TODO : give a explanation of this explicitly ? 

- Memory Mapped Files

  - using **mmap()** on Unix system
  - memory access is faster than I/O system calls
  - can used to implement shared memory in IPC

- VM issues : Page size and Pre-paging

  - page size selection impacts  : Fragmentation, Page Table Size, I/O overhead. Locality
  - Q : How page size influence I/O overhead?
  - Prepaging : bring some pages in memory before referenced.
    - might waste time if some of them are not used. Can reduce number of page faults on process start up.

- VM issues : program structure

  - different code cause varied different memory accesses

- VM issues : I/O interlock

  - maybe when a block is waiting for I/O but another process take up this block because of page fault, the data was lost.
  - solutions : blocks doing I/O cannot be chosen as victim. 
  - solutions : first put data in kernel memory then copy to user memory.
  - or we can lock kernel pages to avoid kernel page faults?
  - Q : I thought kernel pages won't fault so the above solution by using kernel memory can work?  solution 2 implies kernel page won't have faults so it can hold
  - or lock page which got brought in memory but not used yet.

#### 8. File Systems

- Components of file system : 
  - application programs
  - logical file system
  - file-organization module
  - basic file system
  - I/O control

- File Attributes : 
  - name
  - identifier
  - type
  - location
  - size
  - protection
  - Information about files are kept in a directory, each file has an entry in the directory.
  - Q : is directory a file too?

- File Operations
  - Create 
  - Write
  - Read
  - Reposition with in file : 
  - Q what does reposition means
  - Delete
  - Truncate
  - Q what does Truncate mean
  - Other operations can be composed of these primitives
  - To perform these operations , a file must be open.

- Directory : interface
  - directory is a logical group of files
  - a directory contains an entry for each file under it
  - and some systems like Unix treat directories as files

- Directory Operations 
  - search for a file
  - create a file
  - delete a file
  - list a directory
  - rename a file
  - traverse the file system

- Directory Structures
  - Efficiency :  locating a file quickly
  - Naming : 
    - two user can have same for different files
    - same file can have several different names : aliases, links
  - So tree structured directories are the most common
    - paths are intuitive for users
    - Q what does intuitive here means

- Acyclic graph directories

  - problems : when files get deleted, links may still point to it.

- Solutions : symbolic link and hard link
  - symbolic link : leave the dangling pointer for the user to delete
  - Q : what is inode of file
  - hard link : keep a reference count on the file, when are links are deleted the file is deleted
  - Q : what will happen if i recreate a file with same name? will the softlink still point to the file? or they just have the same name?
  - to avoid infinite search, we bypass links during directory traversal

- Mounting : Important
  - OS is given name of the device and a mount point
  - OS checks device to make sure it has a valid file system
  - Q : how OS checks that file system
  - Then OS makes the new file system available

- Virtual File Systems
  - each file system has its own file and directory structure
  - OS implements a virtual file system layer to avoid difference among file systems
  - VFS provides a common interface to all file systems so don't need to worry about which file system so don't worry about which file system we use
    - open()
    - read()
    - write()
    - etc

- Implementation : On disk and In memory
  - On disk 
    - directory stucture
    - number of blocks
    - location of free blocks
    - boot information
  - In memory
    - caching to improve performance
    - manage the file system 
    - Q : what does the manage the file system means? Why in memory file systems

- On-disk structures
  - Boot block
    - information to boot the OS:
    - is boot block used for os to know what type it is ? and mount point ?
  - Volume Control Block : information about  the partition
    - number of blocks,block size, free block count
    - UFS calls it superblock, and NTFS calls master file table
    - UFS : Unix   NTFS : Windows  et2 : Linux
  - Directory Structure 
    - UFS used inodes
    - Q : what is inodes?
    - NTFS stores related info in the master file table
  - File Control Block : FCB
    - size, location of data blocks, file permissions, ownership
    - Q : Where is FCB in UFS,
    - UFS calls it inode, NTFS stores this info to master file table
    - Q : so basically the FCB is located at the start of continuous data blocks of a file?
    - Q : is super block and directory block connected (in adjacent disk space?)

- In memory structures

  - Mount Table : info on each mounted volume :
    - Q : what does mount table stores? how to use mount table to find a device in Linux
    - Q : describe the whole procedure of using a Mount Table to find a file system
  - Directory Structure Cache : info on recently accessed directories
  - System wide open file table
    - copy of the FCB of each open file in the system
    - info on which process currently using which file
  - Per-process open-file table : contains an entry for each file opened by this process
    - pointer to entry in the system-wide open-file table
    - info regarding the usage of the file by this process : current file pointer, open mode
    - Q : where is current file pointer stored originally ? FCB ?

- Open a file

  - Search the directory to find the file control block
    - may need to bring from disk multiple directory blocks into memory, if they are not already cached
    - create an entry in the per-process open-file table PFT
    - check whether the system-wide open-file table has an entry in this file
      - if does, increments its reference count, and make the entry in PFT  point tothis entry
      - if not, create a new entry in  system-wide open file table, and set reference count to 1
      - Q : when was reference count first mentioned
    - return a pointer (file descriptor / handle?) tp the entry in PFT and continue operation using descriptor

- Creating a file

  - allocate a new file control block
    - Usually FCB are pre-allocated, and find a free FCB is enough
  - Read relevant directory blocks in memory
    - update them to reflect the new file, write them back to disk
    - Q : how a create file really happens ? get current directory or target directory name? find the directory block from disk? and what is the directory block is full that cannot place new FCB in the block ? If finding a new block, are the two blocks continuous?
    - Allocate free blocks for the data of the file

- Allocation methods

  - first : disk allow random access of blocks
  - three methods : contiguous, linked indexed

- Contiguous Allocation

  - each file occupies a set of contiguous blocks
  - need start address and length 
  - will cause external fragmentation, files may not be able to grow

- Linked Allocation

  - a file is a linked list of blocks
  - need start block and end block to append to file
  - expensive random access : must traverse the chain to get to the middle of the file
  - if one block is corrupted, the chain is broken

- Indexed Allocation

  - bring all pointer together into an index blocks
  - but will need extra index block for even small files
  - so use linked index blocks to have a small index block for small index file
  - or using a multilevel index blocks. have shorter access time but more space overhead
  - Combined : Used in Unix file system
    - multilevel and linked
    - each file has an index block (inode) , which contains : pointer that point to data blocks directly (small files) and point to index blocks . (Unix supports three level of index blocks)
    - Q : what is the inode differenct from the FCB inode?

- Example : Unix inode

  - ```c
    fptr = open("/pub/data/file1.txt", "read");
    read(fptr, buf ,4) ; // read 4 bytes
    
    seek(fptr, 12*1024*4 + 4);
    read(fptr, buf, 4)
    ```

  - Q : How many disk operations each of the above lines takes?

    - line 1 : 7
    - line 2 : 1 

  - reading different part of the file may need reading multiple inodes : see line 3 and 4

- Free blocks Location

  - Using bit map : one bit for each block , 0 = occupied, 1 = free
    - bit map is supported by hardware
    - But bit map is stored in disk, very slow access.
    - solution : can cache it in memory but it is not small for large disks
    - so we can group multiple free blocks to reduce bitmap size

- Free space management

  - Linked list : no waste of disk space, but not easy to get contiguous space
    - we can solve this by grouping, addresses of n free blocks are stored in the first block, the last block contains addresses to the following n free blocks
    - keep address of 1st free block and count the following free blocks (very simple, and no need to worry about too many contiguous free blocks cannot be stored in on block)

- Recovery

  - failures : hardware defects, software bugs and external events
  - simple consistency checking, set a bit on dist before metadata is to be update, reset it after metadata update is complete.
  - upon reboot, i bit is set, then crash occurred and invoke consistency checking
  - Log structured file systems
    - each metadata update to FS is a transaction
    - considered committed once written to the log
    - transactions in the log are synchronously written to file system structure
    - when the file system structures are modified on disk, the transaction is removed from the log
    - Q : what does the above sentence means?
    - if file systems crashed, transactions is log are replated

- Network File System (NFS)

  - support different machines, OS , and networks
  - Mount remote directory over local FS directory 
  - Q : how is hierachy mounting performed ? why can mounted to a directory not an OS ? any mechanism in this? block-scale explanation required
  - once mounted, remote directory is accessed transparently?
    - looks like local directory, but all operations are sent over network
  - Heterogeneity
    - RPC (remote procedure call) primiives over
    - Q : where is RPC first mentioned?
    - XDR( External Data  Representation) Protocol
  - Mounting :
    - supports cascading mounts
    - Q : what does this graph means?

#### 9. Storage

- Disk Physical Structure
  - Disk is viewed as a one-dimensional array of logical blocks
  - block = sector
  - block 0 is at the first sector of the first track on the outermost cylinder
  - then traverse through that track , then tracks on that cylinder, then different cylinder
  - block address  <cylinder, track, sector>
  - created through low-level formatting of disk
  - Q : what s low-level formatting?
- Disk Scheduling
  - kernel maps requests to logical block addresses
  - and request are sent to disk controller : Hardware ?
  - Q : is that hardware or software
  - Targets : 
    - Fast disk access time
    - High disk bandwidth : bytes transferred per sec between disk and memory
- Disk Operation
  - Accessing a block
    - Move the head to desired track (seek time)
    - wait for desired sector to rotate under the head(rotational latency time)
    - transfer the block to a local buffer, then to main memory (transfer time)
    - we are trying to minimize the seek time, which is the proportional to the seek distance
- Scheduling Algorithms
  - TODO : this is a problem in the final exam, do it!
  - First Come First Served : Benbi algorithm
  - Shortest Seek Time First : can cause starvation
  - Q : where is this sequence stored? Hardware implement the algorithm ?
  - SCAN: Disk move from on end to other servicing requests!
  - Circular SCAN :treats cylinder as circular lists, if go to end, move to the other end
  - C-LOOK : only go as far as the last request in each direction
- How to select one?
  - Requests for I/o can be influenced by file-allocation mthod
  - SSTF is common and good
  - SCAN and CSCAN perform better that has heavy load on disk
  - SSTF and CLOOK are usually default algorithms

#### 10. Protection

- Principles
  - princeple of least privilege
  - need to know principles : at any time, a process should be able to access resources it requires to complete its task
- Domain of Pretiction
  - domain means set of access rights
  - right-set is a subset of all valid operations that can be performed on the object
  - two allocation method: static and dynamic association
  - dynamic : process can switch from one domian to another to access objects or perform needed operations
- Realizing Domain
  - each user is a domain : depends on user'id
    - user switching to achieve domain switching
  - each process is a domain : depend on process id
    - domain switching : message passing between processes 
    - Q : why message passing can do this
  - each procedure is a domain : depends on local variables
    - Q : any implementing this? weird?
    - domain switching : procedure calls
- Access Matrix
  - TODO : this is important and must do it!
  - Domain switching : need to allow a process to switch domains
  - change entries of access dynamically
    - add/remove/copy rights
  - copy of access right R on object Oi
    - can copy the access right R with same column
    - Q : who has this right?
  - owner of Object O
    - can add remove access rights to Oi
  - control of domain D
    - can add/remove access rights to domain Di
- Policy vs Mechanism
  - Operating system provides access matrix rules
  - Matrix is only manipulated by authorized users
  - Rules are strictly enforced
  - User dicate policy
- Implementation of Access Matrix
  - Global Table : large and sparse
    - Grouping can reduce size
    - Q : how was this done?
    - repetition of access rights for defaults
  - Access Control List : each column(object) has a list of domains that can access it
    - <D1, {Read}>, <D3,{Execute}>
    - can support default rights
    - Q : how was this done?
    - but difficult to determine access rights of a domain
  - Capability List : Each row has a list of objects and what operations are allowed on them
    - But difficult to revoke capabilities of an object
- Revocation of access rights
  - easy with CL but difficult with capability list
  - Back-pointers:
    - pointers maintained with object to capabilities
  - Indirection
    - capabilities point to entry in global table
    - Q : only pointer to a specific place in a global state.
    - Q : why need to searching table and deleting the entry?
  - Reacquisition
    - Periodically delete capability from each domain ?
  - Keys
    - Objects have a master key,
    - capabilities have keys which are copy of master key
    - Revocation done by changing the master key
    - Q : change the master key held by objects? How was this Done? change the domain's key or the object's key?
    - selective revocation done by holding multiple key per object?
    - Q : why is this selective ? 
  - combination of capabilities and ACL.
    - first search ACL ,then if guaranteed then capacity is added to the process. Other access use capabilites list for faster check
    - Q : how is this related to file access? Keep a handle in the process?
  - Protection in Unix
    - Owner : Group : Universe    rwx rwx rwx filename
    - r on dir means can list files, x means can open files
    - can create ACL on demand for complex access control
      - setfacl
      - setuid using chmod u+s / setgid
  - Security
    - Trojan : sear
      - ch paths getting misued? 
      - Q how was this done
      - often related to principle of least privilege
    - Trap door : like back doors
    - Virus

#### 11. Assignments 

#### 12. Problem sets

#### 13. Demos



