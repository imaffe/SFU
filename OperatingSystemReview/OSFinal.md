## Operating Systems Final Review

#### 1. Introduction : kernel & system call

- interrupt
  - interrupt service routine: ISR are stored at a known memory locations。 Interrupt number is mapped to an entry in  interrupt vector where the entry contains the address of an ISR in memory
  - Interrupts are generated by **hardware** devices
- traps
  - traps are software-generated interrupts due to :
    - divide by zero, illegal memory access
    - request for os services(system calls)
- user and kernel
  - kernel mode can execute privileged instructions
  - hardware execute privileged instructions only in kernel mode
    - if not in kernel mode, hardware raises an interrupt, and switch system in kernel mode
    - OS ensures safety and correctness before execution
- system calls : kind of trap
  - Definition : user access privileged instructions using system calls 
    - when interrupt/trap/exception is generated, the control is transferred to the OS
  - API : often executed through API
    - **printf ()** calls **write ()** system call, and mapping is done by standard C library
    - **strace -c ls** can be used to display summary info on system calls invoked during the execution of  the command **ls**
  - Protection : Timer Chip ( Hardware )
    - when the user program use resource more than the set time chip issues interrupt. So this can OS regain the control. Then OS decides to whether give more time or terminate it.
- exception : TODO what is exception
- OS structures
  - Monolithic Structure : Too much in one layer
  - Layered Structure : trick to design the layer if two layer use each other/ each layer use only lower layer service.
  - Microkernel Structure : provide minimal services, rest in user space. Modules communicate using message passing(through kernel),  Easier to extend microkernel and port to new architectures, but will have performance over head.
  - Modular Structure :   Implement OS as separate components, and other modules are linked to kernel as needed. Most OS are implemented this way. Flexible and efficient
  - Hybrid Structures
- System Boot
  - OS must be started by hardware
  - On powered up the instruction register is loaded with a predefined memory location
  - Bootstrap loader routime
    - load the boot block on the disk to memory 
    - boot block load the rest of the loader
    - the loader loads kernel

#### 2. Processes and Threads

##### Process

- Components : at least Program Counter / Stack / Data section

- The Graphic View of a process : in slides 

- Process State 

  - new
  - running : if receive interrupt, it will go to the ready queue
  - waiting ： waiting for some event to occur, like IO  or event completion
  - ready ：process is waiting for CPU scheduler dispatch.
  - terminated
  - TODO : what is the difference between waiting a nd ready

- Process Control Block

  - Components:

    - Process State
    - Program Counter
    - CPU registers
    - CPU scheduling info
    - Memory-management info
    - Accounting Info
    - I/O status

  - Usage : Switch CUP from one process to another

  - PCB in linux 

    ```c
    struct task_struct{
        pid_t pid;
        long state;
        unsigned int time_slice; //scheduling information
        struct task_struct * parent;
        struct list_head children;
        struct files_struct * files; // list of open files
       	struct mm_struct *mm;  // address space of this process
    }
    ```

  - ready queue : set of all processes in main memory, ready to be execute

  - waiting queue : TODO is this reside in disk

  - device queues : processes waiting for I/O device

  - I/O queue : TODO : is I/O queue the same as waiting queue?

  - scheduling queues : TODO the graphical view of the whole procedure

  - Context Switch : save state of one PCB in memory, and load another's information into registers, state means CPU registers like stack pointer and program counter

  - Fast Context Switch : use hardware support with multiple register sets, only need to change pointer to complete context switch

- Process Creation

  - Process Tree : has parents and children

  - **fork()** system call to create a child process. Child is a 很copy of the parent,

  - **exec ()** system call to load another program into its address space.

  - parents wait for children to terminate 

  - Q : can we not wait ? Is is a default wait? what is the NULL in program means

    ```c
    int main(){
        pid_t var_pid;
        var_pid = fork(); 
        // fork and return the pid of the child process to parent
        // return 0 to child process
        if(var_pid < 0){ // error when pid < 0
            fprint (stderr, "fork failed");
            exit(-1);
        }
        else if(var_pid == 0){ // means this is a child process
            
            execlp("/bin/ls", "ls", NULL);
        }
        else{
            // TODO what should the var_pid be : the pid of child?
            wait(NULL);
            printf("Child %d Completed", var_pid);
            exit(0);
        }
    }
    ```

- Process Termination

  - **exit()** execute last statement and ask OS to delete it
  - **abort()** terminate the execution of children process : can have **cascade** termination
  -  zombie process: child terminated but parent hasn't called wait(), and return value stay in mem.
  - orphan process: Parents exited without calling wait(), linux use adoption by init process?
  - Q : what is the '&' operand in shell mean and what was executed when doing this?

##### Threads

- Definition : basic unit of CPU utilization, must have Program Countre, Register set and set at least.

- Share Section : Code section,Data Section, OS resources like open files and signals

- Q : is code section means part reside in disk?

- Q : How signals share among threads ? Who is in charge of allocate signals to threads.

- Thread Models

  - User level threads

    -  All data structures are maintained in user level
    - All thread operations are performed in user mode
    - kernel knows nothing about user-level threads
    - provided by user-level libs

  - Kernel level threads

    - All data structure are maintained in kernel space
    - All thread operations have to be in kernel mode (need system calls to perform them)
    - Provided by the OS

  - Many to One : managing user  threads is faster, no system calls, and no switching to kernel mode

  - One to One : increased concurrency, and when one thread blocks the other can run, but create too many kernSignalsel thread degrade performance because they consume OS resource.

  - Many to Many : Need a thread scheduler. When a user thread blocks, the kernel notifies thread scheduler (using upcall) to select another thread to use the free kernel thread

    ```c
    // Pthread Example
    #include <pthread.h>
    int sum;
    void * runner(void * param){
        int i, upper = atoi(param);
        sum = 0;
        for（i = 1; i <= upper; i++）{
            sum += i;
        }
        pthread_exit(0);
    }
    
    int main(int argc, char * argv[]){
        pthread_t tid;
        pthread_attr_t attr;
        pthread_attr_init(&attr); // using default settings
        pthread_create(&tid, &attr, runner ,argv[1]);
        pthread_join(tid, NULL); // waitign for the thread to be done
    }
    ```

- fork() : if exec() executed right after fork(), no need to duplicate all threads, else all threads should be duplicated

- Signals : synchronous or asynchronous

  - generated by an event, and delivered to a process.

  - Signal handler can be OS or user-defined codeneed to know the formulas

    ```c
    void handle_SIGINT(){
    	// do anything
        exit(0);
    }
    int main(int argc, char * argv[]){
        struct sigaction handler;
        handler.sa_handler = handle_SIGINT; // register handler
        sigaction(SIGINT, &handler, NULL);
        while(1)
       	return 0;
    }
    ```

    - Q : what is the difference between signals and trap? one switch to kernel mode and one might not?
    - asynchronous generated by external event like Ctrl-C. Synchronous generated by threads like division by 0.

  - Threads can choose to block signals.

- TODO : Difference between Interrupts and signals and traps and exceptions

- Thread Pools : very common in modern 

- Linux Thread

  - Do not need to create threads when requried.
  - Linux refers to threads and process as tasks
  - Thread creation is done through **clone** system call
  - clone : 1. can have no sharing resources 2. share of all resources between parent and child. So 1 is like process and 2 is like threads

#### 3. CPU Scheduling

- CPU/IO Burst Cycle
  - Q : where is process in when in I/O wait , waiting queue or ready queue?
- Two or Three level scheduler: 
  - job scheduler decide which processes go to memory(ready queue)
  - CPU scheduler decide which job in ready queue to execute
  - Medium Term scheduler, move some partially-executed jobs from memory to disk.
  - Q : where is I/O queue? what is the difference between I/O queue and waiting queue ? Does I/O queue has a scheduler too? 
- Long-term scheduler (job scheduler)
  - Controls the degree of multiprogramming
  - invoked infrequently
  - job is to maintain a good mix of CPU-bound and I/O bound jobs in the system
- Short Term scheduler (CPU scheduler) : Main Focus
  - invoked very frequently, and must be fast
- Two schema of CPU scheduler
  - preemptive
    - Can force a process to stop at any time of execution.
    - Q : will it be put into ready queue or other places?
    - Preemptive is more difficult to implement because maintain consistency between shared data and it might need hardware support. If preempt a system call it might need to store kernel structures.
  - nonpreemptive
    - does not leave once allocated CPU unless : has to wait like I/O or child process to terminate
    - it self terminates
- Dispatcher : scheduler only point out which to execute, dispatcher do the real work
  - including
    - Context switch
    - switch to user mode
    - jump to proper location
  - Dispatch latency, time it takes for the dispatcher to stop one process and start another
- Scheduling Criteria : strategies
  - Maximize CPU utilization
  - Maximize Throughput
  - Minimize Turnaround Time
  - Minimize Waiting Time
  - Minimize Response Time
- 5 Scheduling Algorithms
  - FCFS : first come first served, will cause convoy effect
  - SJF : shortest job first, need to know the next CPU burst length
    - Burst Length Prediction
    - Q : why do we need to know the next?
  - SRTF : Shortest remaining time first
  - Priority Based : can cause starvation, can use aging to avoid starvation
  - Round Robin : (**important**)
    - total n process, each process execute 1/n time, this time called q.
    - q large : FCFS     q small : high overhead for context switch
    - 80% CPU bursts should be shorter than time quantum
  - Multilevel Queue(**important**)
    - process can change between queues
    - multilevel feedback queue, lower queue run only when higher priority queue is empty
    - 8ms ->16ms ->FCFS , if 8ms RR not finish then move to 2nd queue with 16ms quantum
    - This cause short processes served faster,  and long process sink to bottom FCFS queue bring 
    - more through put
- Multiprocessor Systems:
  - a CPU can has multiple cores, and a core can have multiple kernel threads.
  - Asymmetric multiprocessor : One master processor do the scheduling for others
  - Symmetric multiprocess, each processor run its own scheduler.
- SMP issues
  - Processor Affinity : if bound to a CPU, better not change because cause of context switch is high
  - Load Balancing : guarantee evenly distribution among processors
    - Push migration : a task check load and moving tasks
    - Pull : a free processor pulls a task from busy processor
- Real Time Scheduling
  - Earliest deadline first hard-real-time
  - quickly, priority based scheduling with preemption
- Linux : Completely Fair Schedulers (CFS)
  - select task with lower virtual run time, O(logN) with red-black tree , O(1) with caching

#### 4. IPC & Synchronization

##### Interprocess Communication (IPC)

- Shared Memory : one process creates shared memory, other process attach shared memory to their own memory address
  - POSIX : shm_open(), mmap()
- Message Passing
  - Send messages via **kernel** send(msg), receive(msg)
  - TODO what is Naming vs Ports/Mailbox
  - TODO what is Block vs NonBlocking
  - Buffering

##### Synchronization

- Describe a race condition using  instruction level
- Three condition for solving Critical Section  Problem
  - Mutual Exclusion
  - Progress
  - Bounded Waiting
- Peterson's Solution

#### 5. Deadlocks

#### 6. Memory Management

- Main Memory and register are the only storage that CPU can access directly (caching can be used)
- Three way of binding instruction and data to memory
  - Compile time
  - Load time
  - Execution Time
  - Q : Give a example of load time and execution time 
  - Logical and physical address space differ only binding happens in execution
- Memory Management Unit( MMU)
  - hardware : runtime mapping logical to physical address
  - and ensures memory protection using base and limit registers, only kernel code can change the value of the register
- Memory Allocation : usually divided to 2 part, one for OS one for user processes
  - Contiguous Allocation vs Non-contiguous memory allocation (paging)
- Contiguous Allocation
  - OS maintain information about allocated partitions and free partitions
  - First Fit : find first hole that can hold
  - Best Fit : find smallest hole that can hold
  - Worst Fit : find largest hole that can hold
  - Pros : easy to implement, Cons : Memory Fragmentation
  - Q : Internal or External? External! Internal occurs when paging is used.
  - Can use memory compaction to avoid Memory Fragmentation
- Paging 
  - page table : translate logical to physical addresses
  - Q : where is page table? every process has one? kernel or user keeps this? when was it loaded? why there is paging hardware? 
  - What is paging hardware?
  - Address Translation : Do the math
  - Implementation of Page Table
    - page table is kept in main memory : but this will cause every memory access requires two memory access.
    - TLB : Translation look-aside buffer : stores part of the page table , Hardware
      - if TLB is full need OS to replace. However some entries in TLB are wired down.
      - Each entry stores address space Identifier (ASID) so that entries for different processes can be held simultaneously. 
  - Calculation of Effective access Time.
  - Memory Protection
    - Use several bits to indicate page's authority. Add  another bit valid/invalid bit to indicate whether the page is in the process's address space
    - Q : every process has a page table or has process id to indicate which one belongs to a certain process.
    - illegal memory access will trap to OS
    - Page table length register to limit size
  - Shared pages : shared code, must appear in the same location in the logical address of all process
  - Q : why in the same location in the logical address rather than physical address?
  - Need to know how to calculate the size and structure of a page table.
  - Hierarchical page table implementation, but notice the extra memory access overhead.
    - Why 4 byte entry
  - Hashed Page Tables
    - each element has virtual page number
    - mapped page frame number
    - pointer to next element
  - Inverted Page Table
    - using process id and virtual page number to search the required page.
    - can use hash table to reduce the search time
    - Q : how to use hash table to do this? hash to one of physical memory entries and mark down the physical page number in the list head?
    - But it is difficult to implement shared page
- Segmentation
  - divide memory from user's view
  - Segmentation Architecture
    - <segmentation Number, offset>
    - using segment table to map logical to physical.
    - Each entry has base and limit information to represent a segmentation
    - every time a logical address is checked if beyond segmentation
    - Cons : dynamic memory allocation problem. External Fragmentation
    - Can combine segmentation with paging
- Intel 32  architecture
  - use both segmentation and paging
  - first go to segmentation to produce a linear address
  - linear address given to paging unit to generate physical address
  - Q : do we have a segmentation table for each process ? and load it as the page table?
  - Segment up to 4 GB (2^32 byte)
  - Max number of segments per process 2^14 half for private , half for shared 
  - 13 bit seg, 1 bit private or shared, 2 bit for page?
  - Q : what does the q mean of the last 2 bits
  - Pagesize 4KB or 4 MB; Two level paging : 10 for page table 1, 10 bit for page table 2, 12 for offset.
- Page Address Extensions (PAE)
  - Q : What does base address mean? Added a extra register to denote which part?

#### 7. Virtual Memory

- Process Virtual Address Space

  - Q : is the graph show the logical memory? why do we load shared libraries and where would libs belong to if not this structure? Which part should libs belong to?

- Demand Paging

  - valid-invalid bit to denote whether in memory or not
    - Q : how to decide whether it is Page Fault or illegal reference of memory?
    - TODO how many memory access would occur if the worst case in a Page Fault ?
  - **Important**  how to handle restart instruction causing overlapping? and solution
  - Major latency comes from reading new page from disk **pay attention to units !! milliseconds**
  - Copy-on-write technique : act when doing fork()

- Major vs Minor page fault

  - major : need to bring page from disk

  - minor, do not need to bring page from disk, like shared page that just hasn't been linked but already in memory or dynamic memory allocation where kernel may not actually allocate physical memory until it is accessed.

    ```shell
    # some commands
    ps -eo min_flt,maj_flt,pid,cmd
    /usr/bin/time -v ls
    vmstat
    getconf PAGESIZE
    ```

- Page Replace Algorithms

  -  Q : how many system calls during a certain execution? How many will happen when a page replacement happen. Which mode OS is in when doing each stage.
  - FIFO : cause Belady's Anomaly
  - Optimal : Do some exercise
  - LRU
    - counters implementation : but will has overflow, need hardware support
    - stack: need hardware support
    - cannot use software because interrupts are very costly
  - CLOCK
  - LFU and MFU

- Allocation of frames : how many pages a process at least have

  - Proportional allocation using priorities rather than size
  - Global replacement : choose from all frames, can take frame from other process
  - Local replacement: can have have page fault rage even other process has extra
  - Q : local replacement means the it only replace its own frames.

- Thrashing

  - leads to : low  CPU utilization and more page switching than executing.
  - Models to solve Thrashing : Locality Model : decide the most recently used codes
  - Working-Set model.
    -  OS monitors the WS of each process
    - allocate WS size number of frames to each process
    - if we have left memory space we can start another process
    - TODO : the way to estimate the size of WS with interval timer and reference bit
  - Another way to control thrasing : using page fault rate
    - monitor page-fault rate and add frame or delete accordingly
    - Q : is this Global Allocation?

- Allocating Kernel Memory

  - some kernel memory needs to be continuous,
  - kernel will keep structures !
  - Q : why structures make kernel special? because dynamically allocated
  - virtual memory is expensive for kernel memory

- Using Free Frame Pool to kernel pool

  - Buddy system
    - using sub blocks using power-of-2 size. and can combine adjacent blocks
  - Slab system
    - a slab is one or more physically contiguous pages
    - a cache is for each unique kernel data structure
    - no fragmentation and fast memory allocation
    - TODO : give a explanation of this explicitly ? 

- Memory Mapped Files

  - using **mmap()** on Unix system
  - memory access is faster than I/O system calls
  - can used to implement shared memory in IPC

- VM issues : Page size and Pre-paging

  - page size selection impacts  : Fragmentation, Page Table Size, I/O overhead. Locality
  - Q : How page size influence I/O overhead?
  - Prepaging : bring some pages in memory before referenced.
    - might waste time if some of them are not used. Can reduce number of page faults on process start up.

- VM issues : program structure

  - different code cause varied different memory accesses

- VM issues : I/O interlock

  - maybe when a block is waiting for I/O but another process take up this block because of page fault, the data was lost.
  - solutions : blocks doing I/O cannot be chosen as victim. 
  - solutions : first put data in kernel memory then copy to user memory.
  - or we can lock kernel pages to avoid kernel page faults?
  - Q : I thought kernel pages won't fault so the above solution by using kernel memory can work?  solution 2 implies kernel page won't have faults so it can hold
  - or lock page which got brought in memory but not used yet.

#### 8. File Systems

- Components of file system : 
  - application programs
  - logical file system
  - file-organization module
  - basic file system
  - I/O control
- File Attributes : 
  - name
  - identifier
  - type
  - location
  - size
  - protection
  - Information about files are kept in a directory, each file has an entry in the directory.
  - Q : is directory a file too?
- File Operations
  - Create 
  - Write
  - Read
  - Reposition with in file : 
  - Q what does reposition means
  - Delete
  - Truncate
  - Q what does Truncate mean
  - Other operations can be composed of these primitives
  - To perform these operations , a file must be open.
- Directory : interface
  - directory is a logical group of files
  - a directory contains an entry for each file under it
  - and some systems like Unix treat directories as files
- Directory Operations 
  - search for a file
  - create a file
  - delete a file
  - list a directory
  - rename a file
  - traverse the file system
- Directory Structures
  - Efficiency :  locating a file quickly
  - Naming : 
    - two user can have same for different files
    - same file can have several different names : aliases, links
  - So tree structured directories are the most common
    - paths are intuitive for users
    - Q what does intuitive here means
- Acyclic graph directories
  - problems : when files get deleted, links may still point to it.
- Solutions : symbolic link and hard link
  - symbolic link : leave the dangling pointer for the user to delete
  - Q : what is inode of file
  - hard link : keep a reference count on the file, when are links are deleted the file is deleted
  - Q : what will happen if i recreate a file with same name? will the softlink still point to the file? or they just have the same name?
  - to avoid infinite search, we bypass links during directory traversal
- Mounting : Important
  - OS is given name of the device and a mount point
  - OS checks device to make sure it has a valid file system
  - Q : how OS checks that file system
  - Then OS makes the new file system available
- Virtual File Systems
  - each file system has its own file and directory structure
  - OS implements a virtual file system layer to avoid difference among file systems
  - VFS provides a common interface to all file systems so don't need to worry about which file system so don't worry about which file system we use
    - open()
    - read()
    - write()
    - etc
- Implementation : On disk and In memory
  - On disk 
    - directory stucture
    - number of blocks
    - location of free blocks
    - boot information
  - In memory
    - caching to improve performance
    - manage the file system 
    - Q : what does the manage the file system means? Why in memory file systems
- On-disk structures
  - Boot block
    - information to boot the OS:
    - is boot block used for os to know what type it is ? and mount point ?
  - Volume Control Block

#### 9. Storage

#### 10. Protection

#### 11. Assignments 

#### 12. Problem Sets

#### 13. Demos



